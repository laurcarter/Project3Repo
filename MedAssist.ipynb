{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9338941,"sourceType":"datasetVersion","datasetId":5659416}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"W-hLaNV3QOiS","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:19.659572Z","iopub.execute_input":"2024-11-11T14:15:19.660704Z","iopub.status.idle":"2024-11-11T14:15:21.198821Z","shell.execute_reply.started":"2024-11-11T14:15:19.660655Z","shell.execute_reply":"2024-11-11T14:15:21.19781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/medquad-medical-question-answer-for-ai-research/medquad.csv\")\ndf = df.dropna()\n\n#df = df.sample(2000)\n#df = df.reset_index()\n#df = df.drop('index',axis =1)\ndisplay(df.shape)\ndf.head()","metadata":{"id":"4SQCcGX3RCWW","outputId":"00236b13-f7b6-4fbc-8c3d-53bf370f35bd","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:21.207238Z","iopub.execute_input":"2024-11-11T14:15:21.207533Z","iopub.status.idle":"2024-11-11T14:15:21.474936Z","shell.execute_reply.started":"2024-11-11T14:15:21.2075Z","shell.execute_reply":"2024-11-11T14:15:21.473933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming 'df' is your input DataFrame\nfocus_area_counts = df['focus_area'].value_counts()\nfocus_areas = focus_area_counts[focus_area_counts > 15].index\n\nfig, ax = plt.subplots(figsize=(20, 8))\nsns.set(font_scale=1.2)\n\nax.pie(focus_area_counts[focus_areas], labels=focus_areas, autopct='%1.1f%%')\nax.set_title('Pie Chart of Focus Areas')\nax.axis('equal')  # Equal aspect ratio ensures that pie is circular.\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:54:52.086285Z","iopub.execute_input":"2024-11-11T14:54:52.08673Z","iopub.status.idle":"2024-11-11T14:54:52.595542Z","shell.execute_reply.started":"2024-11-11T14:54:52.086687Z","shell.execute_reply":"2024-11-11T14:54:52.594537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\n\n# ANSI color codes\n\ncolor_codes = {\n\n    \"blue\": 34,\n    \"green\": 32,\n    \"red\": 31,\n    \"purple\": 35,\n    \"orange\": 33,\n    \"yellow\": 33,\n    \"pink\": 35,\n    \"brown\": 33,\n    \"gray\": 37\n}\n\n\n\nfor i in range(0, len(df), 7):\n\n    color = random.choice(list(color_codes.values()))\n\n    print(f\"\\033[1;{color}mThe question is: {df['question'][i]}\\033[0m\\n\\033[1;{color}m The answer is: {df['answer'][i]}\\033[0m\\n\")\n\n    if i > 30:\n\n        break","metadata":{"id":"wjgQLAyoRger","outputId":"163fe330-09aa-4f9a-d1e9-5f06321c8383","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:21.641414Z","iopub.execute_input":"2024-11-11T14:15:21.641722Z","iopub.status.idle":"2024-11-11T14:15:21.650165Z","shell.execute_reply.started":"2024-11-11T14:15:21.641688Z","shell.execute_reply":"2024-11-11T14:15:21.649129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers sentence-transformers faiss-cpu","metadata":{"id":"gjevhmrYRliC","outputId":"859415a2-d558-4654-9d6a-1b88c1dbf354","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:21.651412Z","iopub.execute_input":"2024-11-11T14:15:21.651806Z","iopub.status.idle":"2024-11-11T14:15:33.477353Z","shell.execute_reply.started":"2024-11-11T14:15:21.651764Z","shell.execute_reply":"2024-11-11T14:15:33.476155Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\nfrom transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n\n# Question Encoder (for retrieving documents)\nquestion_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\nquestion_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n\n# Context Encoder (for encoding the documents in the knowledge base)\ncontext_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\ncontext_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')","metadata":{"id":"iDHsZtFBTTmK","outputId":"b1bd0283-5612-4eef-ff5c-dd22dfa1332f","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:33.479535Z","iopub.execute_input":"2024-11-11T14:15:33.480611Z","iopub.status.idle":"2024-11-11T14:15:38.219487Z","shell.execute_reply.started":"2024-11-11T14:15:33.480559Z","shell.execute_reply":"2024-11-11T14:15:38.218556Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nfrom sentence_transformers import SentenceTransformer\nimport torch\n\n# Generator model\ngenerator = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\ngenerator_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')","metadata":{"id":"5RTSMA9WTYB9","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:38.220782Z","iopub.execute_input":"2024-11-11T14:15:38.221322Z","iopub.status.idle":"2024-11-11T14:15:44.234625Z","shell.execute_reply.started":"2024-11-11T14:15:38.221268Z","shell.execute_reply":"2024-11-11T14:15:44.233756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_focus_areas = df['focus_area'].unique()\n\n# Filter for focus areas with more than 50 occurrences\nfiltered_focus_areas = df['focus_area'].value_counts()[df['focus_area'].value_counts() > 15]\n\n\n# Get the top 1000\nselected_focus_areas = filtered_focus_areas.head(1000)\n\n# Print the selected focus areas\nselected_focus_areas\n\nnew_df = pd.DataFrame()\n\nfor focus_area in selected_focus_areas.index:\n    # Filter the original DataFrame for the current focus area\n    focus_area_df = df[df['focus_area'] == focus_area]\n\n    # Sample 20 rows from the filtered DataFrame\n    sampled_df = focus_area_df.sample(n=min(20, len(focus_area_df))) # Ensure we don't try to sample more than exist\n\n    # Concatenate the sampled rows to the new DataFrame\n    new_df = pd.concat([new_df, sampled_df])\n\n# Now 'new_df' contains up to 20 samples from each of the selected focus areas.\ndisplay(new_df.shape)\n\nnew_df.head()","metadata":{"id":"hebW2IK_YqXI","outputId":"c68878eb-0bb3-4d77-8721-ac78c15dcef7","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:44.235878Z","iopub.execute_input":"2024-11-11T14:15:44.236537Z","iopub.status.idle":"2024-11-11T14:15:44.365194Z","shell.execute_reply.started":"2024-11-11T14:15:44.2365Z","shell.execute_reply":"2024-11-11T14:15:44.364241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" encoded_docs = []\nfor index, row in new_df.iterrows():\n\n    inputs = context_tokenizer(row['answer'], return_tensors='pt', truncation=True, max_length=512)\n\n    with torch.no_grad():\n\n        doc_embedding = context_encoder(**inputs).pooler_output\n\n    encoded_docs.append(doc_embedding.numpy())","metadata":{"id":"gt4ooVgvThwT","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:15:44.383336Z","iopub.execute_input":"2024-11-11T14:15:44.383711Z","iopub.status.idle":"2024-11-11T14:18:15.112438Z","shell.execute_reply.started":"2024-11-11T14:15:44.383677Z","shell.execute_reply":"2024-11-11T14:18:15.111283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import faiss\n\nimport numpy as np\n\n\n\nencoded_docs = np.array([embedding.reshape(1,-1) for embedding in encoded_docs]) # Reshape each embedding to (1, embedding_dimension)\n\nencoded_docs = np.vstack(encoded_docs) # Stack the reshaped embeddings into a single array\n\n\n\n# Now proceed with indexing\n\ndimension = encoded_docs.shape[1]  # Get the embedding dimension\n\nindex = faiss.IndexFlatIP(dimension)  # Using Inner Product (dot-product) for similarity\n\nindex.add(encoded_docs)","metadata":{"id":"2YRMX3s-bwy_","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:18:15.116891Z","iopub.execute_input":"2024-11-11T14:18:15.117396Z","iopub.status.idle":"2024-11-11T14:18:15.161998Z","shell.execute_reply.started":"2024-11-11T14:18:15.117349Z","shell.execute_reply":"2024-11-11T14:18:15.161036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Retrieval-Augmented Generation (RAG) \n\nRetrieval-Augmented Generation (RAG) is a technique that combines the strengths of large language models (LLMs) with the power of information retrieval to produce more accurate, relevant, and informative responses to user queries.\n\n![](https://global.discourse-cdn.com/openai1/original/4X/8/f/f/8ffadd37d90228cdbded952f027d75155fb69391.jpeg)\n   \n## How RAG Works:\n\n- **Query Understanding:** The LLM first processes the user's query to understand its intent and meaning.\n- **Document Retrieval:** Based on the query, a document retrieval system searches a knowledge base or external data source to find relevant information.   \n- **Contextual Augmentation:** The retrieved information is then integrated with the original query to create a more comprehensive context for the LLM.   \n- **Response Generation:** The LLM uses the augmented context to generate a response that is more accurate, relevant, and informative than it would be without the additional information.\n\n\n## Benefits of RAG:\n\n- **Improved Accuracy:** RAG helps LLMs access and incorporate factual information, reducing the likelihood of hallucinations or generating incorrect responses.   \n- **Enhanced Relevance:** By retrieving relevant information, RAG ensures that the LLM's responses are directly related to the user's query.   \n- **Increased Informativeness:** RAG allows LLMs to provide more detailed and comprehensive responses by leveraging external knowledge sources.   \n- **Adaptability:** RAG can be applied to various domains and industries, making it a versatile tool for many applications.\n\n## Use Cases of RAG:\n\n- **Customer Service Chatbots:** RAG-powered chatbots can access a knowledge base of product information, FAQs, and customer support guidelines to provide accurate and helpful responses.   \n- **Search Engines:** RAG can enhance search engine results by providing more relevant and informative summaries of web pages.   \n- **Content Creation:** RAG can assist in content creation by suggesting relevant facts, statistics, and citations.   \n- **Healthcare:** RAG can help doctors and researchers access and analyze medical literature to improve diagnosis and treatment.\n\n \n## Challenges and Considerations:\n\n- **Data Quality:** The quality of the retrieved information is crucial for the effectiveness of RAG. It's important to ensure that the knowledge base is accurate, up-to-date, and relevant.\n- **Model Bias:** LLMs can inherit biases from the data they are trained on. It's important to be aware of these biases and take steps to mitigate them.   \n- **Computational Cost:** RAG can be computationally expensive, especially when dealing with large knowledge bases and complex queries.\n- **Privacy Concerns:** When accessing and processing sensitive information, it's important to consider privacy implications and implement appropriate safeguards.\n\nOverall, RAG is a powerful technique that has the potential to significantly improve the capabilities of LLMs. By combining the strengths of both retrieval and generation, RAG can help create more intelligent and informative AI systems","metadata":{}},{"cell_type":"code","source":"%%time\n\n\ndef rag(query):\n\n    # Tokenize the question\n\n    question_inputs = question_tokenizer(query, return_tensors='pt')\n\n    with torch.no_grad():\n\n        # Embeddings\n\n        question_embedding = question_encoder(**question_inputs).pooler_output.numpy()\n\n    # Retrieve indexes of top 2 documents\n\n    top_k = 2\n\n    _, indices = index.search(question_embedding, top_k)\n\n    retrieved_docs = [new_df['answer'].iloc[idx] for idx in indices[0]] # Use new_df and iloc\n\n    # Concatenate retrieved documents with the query as input for the generator\n\n    context = \" \".join(retrieved_docs)\n\n    input_text = query + \" \" + context\n\n    # Generate a response using the generator model\n\n    inputs = generator_tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n\n    output_ids = generator.generate(**inputs, max_length=20, num_beams=5, early_stopping=True)\n\n    answer = generator_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n    return answer","metadata":{"id":"CsHFH0LmcTDy","outputId":"c0eb893d-6b8b-4f7b-9f44-36af11a92ab8","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:18:15.163654Z","iopub.execute_input":"2024-11-11T14:18:15.16406Z","iopub.status.idle":"2024-11-11T14:18:15.173914Z","shell.execute_reply.started":"2024-11-11T14:18:15.164014Z","shell.execute_reply":"2024-11-11T14:18:15.173005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['focus_area'].value_counts()","metadata":{"id":"Ijv0dXiSiVIF","outputId":"baca5260-2d6b-4458-8841-de2dd4dd1921","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:18:15.175369Z","iopub.execute_input":"2024-11-11T14:18:15.175989Z","iopub.status.idle":"2024-11-11T14:18:15.204404Z","shell.execute_reply.started":"2024-11-11T14:18:15.175951Z","shell.execute_reply":"2024-11-11T14:18:15.202891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming 'df' is your input DataFrame\nfocus_area_counts =new_df['focus_area'].value_counts()\nfocus_areas = focus_area_counts[focus_area_counts > 15].index\n\nfig, ax = plt.subplots(figsize=(20, 8))\nsns.set(font_scale=1.2)\n\nax.pie(focus_area_counts[focus_areas], labels=focus_areas, autopct='%1.1f%%')\nax.set_title('Pie Chart of Focus Areas')\nax.axis('equal')  # Equal aspect ratio ensures that pie is circular.\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:55:54.001303Z","iopub.execute_input":"2024-11-11T14:55:54.001724Z","iopub.status.idle":"2024-11-11T14:55:54.503335Z","shell.execute_reply.started":"2024-11-11T14:55:54.001688Z","shell.execute_reply":"2024-11-11T14:55:54.50237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is the Breast Cancer?\"\n\nresponse = rag(query)\n\nprint(\"Question:\", query)\nprint(\"Response:\", response)","metadata":{"id":"4dF84BlMdjx_","outputId":"3151715e-cc49-408a-fb33-5e4c062f00a9","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:18:15.207229Z","iopub.execute_input":"2024-11-11T14:18:15.208113Z","iopub.status.idle":"2024-11-11T14:18:17.883387Z","shell.execute_reply.started":"2024-11-11T14:18:15.20806Z","shell.execute_reply":"2024-11-11T14:18:17.882268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is COPD?\"\n\nresponse = rag(query)\n\nprint(\"Question:\", query)\nprint(\"Response:\", response)","metadata":{"id":"X6YGIImZiKB1","outputId":"2f9ef122-2cf7-4573-e71d-a903f07a7fa3","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:18:17.884544Z","iopub.execute_input":"2024-11-11T14:18:17.884902Z","iopub.status.idle":"2024-11-11T14:18:20.854969Z","shell.execute_reply.started":"2024-11-11T14:18:17.884864Z","shell.execute_reply":"2024-11-11T14:18:20.853807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is Osteoporosis?\"\n\nresponse = rag(query)\n\nprint(\"Question:\", query)\nprint(\"Response:\", response)","metadata":{"id":"MJQmq3w5ijqy","outputId":"40a7559b-483a-4bf9-e76b-ecdb5d50f2d2","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:18:20.856167Z","iopub.execute_input":"2024-11-11T14:18:20.856506Z","iopub.status.idle":"2024-11-11T14:18:25.771759Z","shell.execute_reply.started":"2024-11-11T14:18:20.856469Z","shell.execute_reply":"2024-11-11T14:18:25.770731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is High Blood Pressure?\"\n\nresponse = rag(query)\n\n\nprint(f\"\\033[1;31mQuestion:\\033[0m \\033[1;36m{query}\\033[0m\")\nprint(f\"\\033[1;31mResponse:\\033[0m \\033[1;36m{response}\\033[0m\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T14:57:47.100682Z","iopub.execute_input":"2024-11-11T14:57:47.101094Z","iopub.status.idle":"2024-11-11T14:57:49.700876Z","shell.execute_reply.started":"2024-11-11T14:57:47.101058Z","shell.execute_reply":"2024-11-11T14:57:49.699886Z"}},"outputs":[],"execution_count":null}]}